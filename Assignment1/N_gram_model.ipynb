{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    sentences = f.readlines()  # Get list of sentences in training set\n",
    "\n",
    "    corpus = \"\"\n",
    "    for i in range(len(sentences)):\n",
    "        sentences[i] = \"<s> \" + sentences[i].replace(\"\\n\", \" </s> \") # Add start and end of sentence tag\n",
    "        corpus = corpus + sentences[i]  # Concatenate each sentence to the corpus\n",
    "\n",
    "    tokens = corpus.split(\" \")  # Get list of individual tokens\n",
    "\n",
    "    token_count = {}\n",
    "    for token in tokens: # Count number of occurences of each token\n",
    "        if token in token_count:\n",
    "            token_count[token] += 1\n",
    "        else:\n",
    "            token_count[token] = 1\n",
    "    \n",
    "    for i in range(len(tokens)): # Mark tokens with single occurrence with <unk>\n",
    "        if token_count[tokens[i]] == 1:\n",
    "            tokens[i] = \"<unk>\"\n",
    "\n",
    "    vocabulary = set(tokens)  # get dictionary of tokens used in corpus\n",
    "    return vocabulary, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 23506\n"
     ]
    }
   ],
   "source": [
    "vocabulary, tokens = preprocess(\"train.txt\")\n",
    "print(\"Vocabulary size =\",len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Token  Count\n",
      "0  liberty     23\n",
      "1      all   1259\n",
      "2     star     39\n",
      "3      usa     41\n",
      "4     sets    426\n"
     ]
    }
   ],
   "source": [
    "def N_gram_probability_distribution(tokens, N):\n",
    "    frequency = {}\n",
    "    if N == 1:\n",
    "        for token in tokens:\n",
    "            if token == \"<s>\" or token == \"</s>\" or token == \"<unk>\":\n",
    "                continue\n",
    "            if token in frequency:\n",
    "                frequency[token] += 1\n",
    "            else:\n",
    "                frequency[token] = 1\n",
    "    else:\n",
    "        probability = 1\n",
    "\n",
    "    x = pd.DataFrame(frequency.items(), columns=[\"Token\", \"Count\"])\n",
    "    print(x.head())\n",
    "\n",
    "\n",
    "N = int(input())\n",
    "N_gram_probability_distribution(tokens, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = \"food\"\n",
    "# sequence = sentence.split(\" \")\n",
    "# N = int(input())\n",
    "# probability = compute_N_gram_probability(sequence, tokens, N)\n",
    "# print(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(sentence, tokens):\n",
    "    count = 0\n",
    "    N=len(sentence)\n",
    "    for i in range(len(tokens)-N+1):\n",
    "        ok=True\n",
    "        for j in range(i,i+N):\n",
    "            if tokens[j]!=sentence[j-i]:\n",
    "                ok=False\n",
    "                break\n",
    "        if ok:\n",
    "            print(tokens[i:i+N])\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(sentence, N, vocabulary, tokens):\n",
    "    sentence = \"<s> \"+sentence\n",
    "    sentence = sentence.split(\" \")\n",
    "    sentence = sentence[len(sentence)-N+1:]\n",
    "    denominator = get_count(sentence, tokens)\n",
    "    prediction_count = {}\n",
    "    for word in vocabulary:\n",
    "        sentence.append(word)\n",
    "        prediction_count[word]=get_count(sentence,tokens)\n",
    "        sentence.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me', 'to', 'do']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bbiswabasu/OneDrive/Sem 7/Natural Language Processing/Assignments/Assignment1/N_gram_model.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=0'>1</a>\u001b[0m generate_sentence(\u001b[39m\"\u001b[39;49m\u001b[39mhe told me to do\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m4\u001b[39;49m,vocabulary,tokens)\n",
      "\u001b[1;32m/home/bbiswabasu/OneDrive/Sem 7/Natural Language Processing/Assignments/Assignment1/N_gram_model.ipynb Cell 8\u001b[0m in \u001b[0;36mgenerate_sentence\u001b[0;34m(sentence, N, vocabulary, tokens)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m vocabulary:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=7'>8</a>\u001b[0m     sentence\u001b[39m.\u001b[39mappend(word)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=8'>9</a>\u001b[0m     prediction_count[word]\u001b[39m=\u001b[39mget_count(sentence,tokens)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=9'>10</a>\u001b[0m     sentence\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;32m/home/bbiswabasu/OneDrive/Sem 7/Natural Language Processing/Assignments/Assignment1/N_gram_model.ipynb Cell 8\u001b[0m in \u001b[0;36mget_count\u001b[0;34m(sentence, tokens)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(tokens)\u001b[39m-\u001b[39mN\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=4'>5</a>\u001b[0m     ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i,i\u001b[39m+\u001b[39;49mN):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=6'>7</a>\u001b[0m         \u001b[39mif\u001b[39;00m tokens[j]\u001b[39m!=\u001b[39msentence[j\u001b[39m-\u001b[39mi]:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bbiswabasu/OneDrive/Sem%207/Natural%20Language%20Processing/Assignments/Assignment1/N_gram_model.ipynb#ch0000007?line=7'>8</a>\u001b[0m             ok\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_sentence(\"he told me to do\", 4,vocabulary,tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
